\chapter{下一步的研究设想}

\section{研究动机}

作者现阶段的研究设想均与机器学习模型部署相关。一个是利用新的云计算服务模式FaaS进行模型部署，另一个是在安全计算环境SGX中进行模型部署。二者所要达到的目的也类似，即在保证服务质量的前提下，尽量提升集群的资源利用率。

\subsection{基于FaaS的模型部署系统现状}
serverless是一种非常适合部署ML模型的计算模式，其具有计费粒度细、横向拓展能力强的特点。但是现有的serverless框架用来部署ML模型时，仍然存在一定的问题；
\begin{itemize}
    \item 当前公有云的serverless服务仅使用CPU，单个servereless实例没有并发能力，能够满足的吞吐量有限。而横向拓展又会因为冷启动造成延迟增加，可能会违背任务的SLO。
    \item serverless一般是基于容器技术实现的（例如Docker等）。而容器使用GPU一般是独占的方式（nvidia-docker），这样会造成显存浪费。通过实验可以证明，在满足一定SLO的前提下，batching的上限距离显存大小仍有一定的差距。
\end{itemize}

如果能解决上述问题，将GPU共享机制和基于SLO的显存调度机制引入serverless系统中，可能可以在保证服务质量的前提下大幅提升系统的资源利用率。

\subsection{基于SGX的模型部署系统现状}
基于SGX的模型部署系统在真实场景中有着广泛的需求，尽管学术界已经在这方面做了一些探索，但是仍有如下问题需要解决：
\begin{itemize}
    \item 由于SGX目前所支持的EPC大小有限，共同部署在同一个EPC内的模型之间可能会存在干扰。
    \item 由于SGX本身的封闭性，对于部署SGX的Enclave内部的应用很难直接对其EPC利用率进行直接监测，从而获得该应用的行为信息（例如内存利用率的变化模式）。
\end{itemize}

如果能解决上述问题，通过一个工具预测应用在SGX环境下的干扰情况，再基于此实现调度算法，则可以在保证SGX环境下模型部署服务质量的前提下，提升SGX集群的资源利用率。

%\subsection{基于线下数据建模的云资源配置推荐现状}

\section{研究设想}

\subsection{SLO可感知的Serverless机器学习模型部署系统}
为了让用户在云上在满足SLO的条件下更经济高效地使用serverless部署ML模型，本文拟提出一种SLO可感知的基于GPU显存共享的serverless框架，解决如下问题：
\begin{itemize}
    \item 实现一种基于API截取的GPU显存共享中间件，使得多个容器可以共享同一块GPU，且相互之间隔离。
    \item 使用GPU的serverless实例时，根据服务的SLO计算其能容许的batching的请求上限，划分一块显存给其使用。
    \item 基于上述机制，实现一种SLO可感知的服务调度算法，将若干服务按照其SLO对应的显存上限进行调度，使多个服务可以在一个GPU设备上共存，提高系统资源利用率。
\end{itemize}

\subsection{SGX环境下机器学习模型部署干扰及调度策略研究}
为了能在SGX更高效地部署机器学习模型，本文拟提出一种SGX环境下机器学习模型部署干扰的建模方法，以及基于此的模型部署服务调度算法：
\begin{itemize}
    \item 在非SGX的环境中对应用（此处的应用对应机器学习模型部署服务）运行时系统信息（例如CPU利用率的变化曲线，与内存相关的指标如换页频率、内存利用率的变化曲线）进行收集，分析应用的行为模式。
    \item 在SGX的环境中部署多个应用，研究其相互干扰的情况。
    \item 将上述两个信息利用模型建立关系，得到一个预测应用之间干扰程度的工具。
    \item 利用上述工具，实现一种SGX环境下的应用调度算法，通过对应用在非SGX环境中采集少许运行时数据，预测其可能与系统中现存的服务之间的干扰关系，将其调度到最合适的节点上。
\end{itemize}

%\subsection{结合频域信息对数据处理类任务进行更精确的建模}